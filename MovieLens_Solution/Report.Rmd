---
title: "MovieLens_Report"
author: "Ian Gledhill"
date: "03/06/2019"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r main, code = source("Solution.R"), include=FALSE, echo=FALSE}
```

```{r}
library(knitr)
```

\newpage
# Introduction

## Overview
The web site http://www.movielens.org/ allows users to rate films from one to five stars, with half-star ratings allowed. This project aims to utilize the large number of movies, ratings and users available to find a method to predict movie ratings. 

This report describes the process and methodology adopted by the project to analyze the existing movie ratings and to devise a method to predict ratings. The accuracy of the various methods will be compared, the accuracy being indicated by the RMSE (_root mean squared error_) of the predictions of each method.

The project will analyze a dataset of movie ratings to predict what ratings a particular user would give a movie. 

The users are randomly selected and are only identified by a uniquely assigned user id; no demographic and geographic location information is used.

## Dataset

### Source
The source dataset was created by the University of Minnesota from the online movie recommendation service MovieLens (https://movielens.org).
 
It is a large dataset and contains:

* 10,000,054 ratings 

* 95,580 tags 

* 10,681 movies

* 71,567 users

The source files can be obtained from this location:

* https://grouplens.org/datasets/movielens/10m/

This link shows further details, including usage rights provided by the licence:

* http://files.grouplens.org/datasets/movielens/ml-10m-README.html

### Sample Size for Analysis
This is a very large dataset and for the sake of managability a 10% sample of the source dataset will be used by the project. The source dataset is circa 1M ratings so the sample dataset will be approximately 100K ratings. 

### Shape of the Data

The source data contains three data sets:

* Movies

* Ratings

* Tags

### Training and Test Data Partitions
The full approach is described later in this report but in summary the sample data is split into two partitions.
A *training partition* will be allocated *80%* of the sample data and will be used to create (or _train_) the algorithm. 
A *test partition* will be allocated the remaining *20%* of the sample data and will be used to validate the predictions of the algorithm.


## Goal
The objective of the project is to find a movie recommendation algorithm. Its success will be measured by reference to the RMSE produced when the algorithm is validated against the test dataset. The RMSE will be graded against a predefined set of thresholds to determine the overall quality of the algorithm (described later).



\newpage
# Approach

## Data Cleansing

## Modelling Techniques

The algorithm will start from a naive position and then be refined as further insights into the data are gained. The effect of each refinement will be accessed using a loss function. The RMSE will be used as the loss function for this project.

### Version 1 : Naive Implementation
The first attempt will use the average movie rating of the training data to predict the rating in the test data. The RMSE will then be measured. The formula for Y (the prediction) is described as follows, where u is the user, i is the movie, ${\mu}$ is the average and ${\epsilon}$ is the error.

$$
\begin{aligned}
 Y_{u,i} &= \mu + \epsilon_{u,i}
\end{aligned}
$$

The result for this is shown here:

```{r movie_mean}
kable(head(rmse_results,1), caption="Results for method 1")
```

### Version 2 : Consider the individual movie effect 
This modification will use the mean with the addition of a movie effect to take into account that some movies are rated more favourably than others. For example, the top 5 best rated and bottom 5 worst rated movies are shown below:

```{r movie_best_rated}
kable(head(movies_by_mean,5), caption="Top 5 Movies - Best Rated")
```


```{r movie_worst_rated}
kable(tail(movies_by_mean,5), caption="Top 5 Movies - Worst Rated")
```

We can see that some movies are rated very highly. For example `r best_movie$title` has an average rating of `r best_movie$average` stars whilst `r worst_movie$title` only has `r worst_movie$average`. The best and worst movies are not necessarily the most and least frequently rated. The top 5 and bottom 5 movies by number of ratings are shown below:


```{r movie_most_rated}
kable(head(movies_by_n,5), caption="Top 5 Movies - Most Number of Ratings")
```


```{r movie_least_rated}
kable(tail(movies_by_n,5), caption="Top 5 Movies - Least Number of Ratings")
```

We can see that some movies are rated very often. For example `r most_movie$title` has `r most_movie$n` ratings whilst `r least_movie$title` only has `r least_movie$n`. 

If we plot the mean against the number of ratings we can see that the extremities (1 star and 5 star) are only obtained by movies with a small number of ratings.

```{r movie_extremtities_have_low_numbers, echo=FALSE}
ggplot(movies, aes(x = average, y = n, size=n, color=n)) +
  geom_point() +
  scale_y_continuous(trans='log10') +
  ggtitle("Average Ratings", subtitle="Extremities occupied by small number of ratings") +
  xlab("Average Rating") +
  ylab("Number of Ratings") +
  theme_minimal()
```

This shows us that movies with a small number of ratings may have a distorting effect.

The formula for Y (the prediction) is described as follows, where u is the user, i is the movie, ${\mu}$ is the average, ${\epsilon}$ is the error and b is the movie effect.

$$
\begin{aligned}
 Y_{u,i} &= \mu + b_i + \epsilon_{u,i}
\end{aligned}
$$


```{r methods_12}
kable(head(rmse_results,2), caption="Results for method 1 and method 2")
```

### Version 3 : Consider the individual user effect 
This is similar to version 2, but instead of looking at the movie effect we are going to examine the user effect; i.e. the fact that some users generally rate movies more generously than others and some users make lots of reviews whilst others make very few.

For example, the top 5 and bottom 5 users based on the average rating given by that user is shown below:

```{r user_best_ratings}
kable(head(users_by_mean,5), caption="Top 5 Users - Highest Average Ratings")
```


```{r user_worst_ratings}
kable(tail(users_by_mean,5), caption="Top 5 Users - Lowest Average Ratings")
```

As with movies we can see that there is variability in both the ratings given (some users appear to be more generous) and the number of ratings the users provide. For example, `r best_user$userId` has given an average rating of `r best_user$average` stars whilst `r worst_user$userId` has given an average rating of only `r worst_user$average`. This might be because user `r worst_user$userId` tends to be make unlucky movie choices and watches poor quality movies. 


```{r user_most_rated}
kable(head(users_by_n,5), caption="Top 5 Users - Most Number of Ratings Provided")
```


```{r user_least_rated}
kable(tail(users_by_n,5), caption="Top 5 Users - Least Number of Ratings Provided")
```


The formula for Y (the prediction) is described as follows, where u is the user, i is the movie, ${\mu}$ is the average, ${\epsilon}$ is the error and b is the movie effect.


$$
\begin{aligned}
 Y_{u,i} &= \mu + b_u + \epsilon_{u,i}
\end{aligned}
$$


```{r methods_123, echo=FALSE}
kable(head(rmse_results,3), caption="Results for method 1, 2 and 3")
```

### Version 4
This will use the combination of the movie effect and the user effect together with an adjustment (a _regulator_) to predict a user's rating.

The formula for Y (the prediction) is described as follows, where u is the user, i is the movie, ${\mu}$ is the average, ${\epsilon}$ is the error and b is the movie effect.

$$
\begin{aligned}
\frac{1}{N} \sum_{u,i} (y_{u,i} - \mu -b_{i})^2 + \lambda \sum_{i} b_{i}^2
\end{aligned}
$$

The value of ${\lambda}$ that leads to the best fit can be determined by trying different values. 

Plotting the RMSE against ${\lambda}$ is shown below:

```{r regulated, echo=FALSE}
ggplot(regulated_data, aes(x = lambdas, y = RMSE)) +
    geom_point() +
    geom_line() +
    ggtitle("Regulated Fit", subtitle="Movie and User") +
    xlab("Regulator Value (Lambda)") +
    theme_minimal()
```


```{r methods_1234, echo=FALSE}
kable(head(rmse_results,4), caption="Results for all 4 methods")
```

\newpage
# Results

The final RMSE values for each of the 4 refinements is shown below. 

```{r methods, echo=FALSE}
ggplot(rmse_results, aes(x = method, y = RMSE)) +
    geom_point() +
    ggtitle("RMSE", subtitle="Changes ") +
    xlab("Method") +
    theme_minimal()
```


\newpage
# Conclusion

The best prediction occurs with the mean modified with the regulated movie and user effect. The majority of the improvement over using a simple mean comes when the user and movie effects are used in tandem. Using both is superior to using either by themselves. Also, the effect of the regulator value is not very significant compared to using just the movie and user effect.

Additional analysis that might increase the prediction accuracy (but not carried out by this project):

Are there additional effects which could be investigated:

* genre : are some genres generally rated hire?

* age : are older films generally rated higher or lower?

* genre combinations : are some genre combinations more likely to rated higher or lower?


\newpage
# Bibliography and References

F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4, Article 19 (December 2015), 19 pages. DOI=http://dx.doi.org/10.1145/2827872 